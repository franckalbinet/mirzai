{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training.plsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & validation (PLSR)\n",
    "\n",
    "> Various utilities function to train and evaluate the Partial Least Squares Regression baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# Python utils\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# mirzai utils\n",
    "from mirzai.data.loading import load_kssl\n",
    "from mirzai.data.selection import (select_y, select_tax_order, select_X)\n",
    "from mirzai.data.transform import (log_transform_y, SNV, TakeDerivative,\n",
    "                                   DropSpectralRegions, CO2_REGION)\n",
    "from mirzai.training.metrics import eval_reg\n",
    "from mirzai.training.core import is_plateau\n",
    "\n",
    "# Data science stack\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from fastcore.test import *\n",
    "from fastcore.transform import compose\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learner():\n",
    "    def __init__(self, data, model):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = data\n",
    "        self.model = model\n",
    "        self.n_cpts_best = 1\n",
    "        \n",
    "    def find_hp(self, n_cpts_range=range(1,10), delta=0.005, verbose=True):\n",
    "        perfs = OrderedDict({'n_cpts': [], 'train': [], 'valid': []})\n",
    "        \n",
    "        for n_cpts in n_cpts_range:\n",
    "            self.model.set_params(model__n_components=n_cpts)\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            perfs['n_cpts'].append(n_cpts)\n",
    "            perfs['train'].append(self.model.score(self.X_train, self.y_train))\n",
    "            perfs['valid'].append(self.model.score(self.X_valid, self.y_valid))\n",
    "            self.n_cpts_best = n_cpts\n",
    "            if (is_plateau(-np.array(perfs['valid']), delta=delta, verbose=verbose)):\n",
    "                return perfs\n",
    "        return perfs\n",
    "    \n",
    "    def fit(self, n_cpts=None):\n",
    "        if not n_cpts:\n",
    "            n_cpts = self.n_cpts_best\n",
    "        self.model.set_params(model__n_components=n_cpts)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def evaluate(self, X, y):\n",
    "        return self.model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PLS_model():\n",
    "    \"Partial Least Squares model runner\"\n",
    "    def __init__(self, X_names, pipeline_kwargs={}):\n",
    "        self.X_names = X_names\n",
    "        self.pipeline_kwargs = pipeline_kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        X, y = data\n",
    "        self.model = Pipeline([\n",
    "            ('snv', SNV()),\n",
    "            ('derivative', TakeDerivative(**self.pipeline_kwargs['derivative'])),\n",
    "            ('dropper', DropSpectralRegions(self.X_names, **self.pipeline_kwargs['dropper'])),\n",
    "            ('model', PLSRegression(**self.pipeline_kwargs['model']))])\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        X, y = data\n",
    "        return (self.model.predict(X), y)\n",
    "\n",
    "    def eval(self, data, is_log=True):\n",
    "        X, y = data\n",
    "        return eval_reg(y, self.model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learners():\n",
    "    def __init__(self, \n",
    "                 tax_lookup,\n",
    "                 seeds=range(20), \n",
    "                 split_ratio=0.1):\n",
    "        store_attr() # see https://fastpages.fast.ai/fastcore\n",
    "         \n",
    "    def train(self,\n",
    "              data,\n",
    "              order=None,\n",
    "              dest_dir_model='',\n",
    "              n_cpts_range=range(2, 10),\n",
    "              delta=1e-2,\n",
    "              early_stop=1e-4,\n",
    "              verbose=True):\n",
    "        \n",
    "        X, y, tax_order = data                \n",
    "        for seed in self.seeds:\n",
    "            print(80*'-')\n",
    "            print(f'Seed: {seed}')\n",
    "            print(80*'-')\n",
    "\n",
    "            #generators = self._get_generators((X, y, tax_order), seed, order=order)\n",
    "            data_train, data_valid, data_test = self._splitter((X, y, tax_order), seed, order)\n",
    "            \n",
    "            model = Pipeline([\n",
    "                ('snv', SNV()),\n",
    "                ('derivative', TakeDerivative(window_length=11, polyorder=1, deriv=1)),\n",
    "                ('dropper', DropSpectralRegions(X_names, regions=CO2_REGION)),\n",
    "                ('model', PLSRegression())])\n",
    "\n",
    "            X_train, y_train, _ = data_train\n",
    "            X_valid, y_valid, _ = data_valid\n",
    "            learner = Learner((X_train, X_valid, y_train, y_valid), model)\n",
    "\n",
    "            learner.find_hp(n_cpts_range=n_cpts_range, delta=delta, verbose=False)\n",
    "            print(f'# of components chosen: {learner.n_cpts_best}')\n",
    "            learner.fit()\n",
    "            with open(dest_dir_model/f'model-seed-{seed}.pickle', 'wb') as f: \n",
    "                pickle.dump(learner.model, f)\n",
    "    \n",
    "    def evaluate(self,\n",
    "                 data,\n",
    "                 order=None,\n",
    "                 src_dir_model=''):\n",
    "        pass\n",
    "        X, y, tax_order = data\n",
    "        perfs = []\n",
    "        y_hats = []\n",
    "        y_trues = []\n",
    "        for fname in glob.glob(str(src_dir_model/'*.pickle')):\n",
    "            with open(fname, 'rb') as f: \n",
    "                model = pickle.load(f)\n",
    "            seed = int(re.search(r'-(\\d+)\\.', fname).group(1))\n",
    "            _, _, data_test = self._splitter((X, y, tax_order), seed, order=order)\n",
    "            X_test, y_test, _ = data_test\n",
    "            y_hat = model.predict(X_test)\n",
    "            perfs.append(eval_reg(y_test, y_hat))\n",
    "            y_hats.append(y_hat.ravel())\n",
    "            y_trues.append(y_test.ravel())\n",
    "        return pd.DataFrame(perfs), pd.DataFrame(y_hats).T, pd.DataFrame(y_trues).T            \n",
    "    \n",
    "    def _splitter(self, data, seed, order=None):\n",
    "        X, y, tax_order = data\n",
    "        \n",
    "        # Train/test split\n",
    "        data = train_test_split(X, \n",
    "                                y, \n",
    "                                tax_order,\n",
    "                                test_size=self.split_ratio,\n",
    "                                random_state=seed) \n",
    "        \n",
    "        X_train, X_test, y_train, y_test, tax_order_train, tax_order_test = data\n",
    "        data_test = X_test, y_test, tax_order_test\n",
    "        \n",
    "        # Further train/valid\n",
    "        data = train_test_split(X_train, \n",
    "                                y_train, \n",
    "                                tax_order_train,\n",
    "                                test_size=self.split_ratio, \n",
    "                                random_state=seed)\n",
    "        X_train, X_valid, y_train, y_valid, tax_order_train, tax_order_valid = data\n",
    "        data_train = X_train, y_train, tax_order_train\n",
    "        data_valid = X_valid, y_valid, tax_order_valid\n",
    "        \n",
    "        if order is not None:\n",
    "            data_train, data_valid, data_test = [self._filter(data, order=order) \n",
    "                                                 for data in [data_train, data_valid, data_test]]\n",
    "            \n",
    "        return data_train, data_valid, data_test\n",
    "    \n",
    "    def _filter(self, data, order=None):\n",
    "        X, y, tax_order = data\n",
    "        mask = tax_order == order\n",
    "        return X[mask, :], y[mask], tax_order[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'test'\n",
    "fnames = ['spectra-features-smp.npy', 'spectra-wavenumbers-smp.npy', \n",
    "          'depth-order-smp.npy', 'target-smp.npy', \n",
    "          'tax-order-lu-smp.pkl', 'spectra-id-smp.npy']\n",
    "\n",
    "X, X_names, depth_order, y, tax_lookup, X_id = load_kssl(src_dir, fnames=fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Seed: 0\n",
      "--------------------------------------------------------------------------------\n",
      "# of components chosen: 44\n",
      "--------------------------------------------------------------------------------\n",
      "Seed: 1\n",
      "--------------------------------------------------------------------------------\n",
      "# of components chosen: 48\n"
     ]
    }
   ],
   "source": [
    "dest_dir_model = Path('test/dumps-test/plsr/train_eval/all/models')\n",
    "seeds = range(2)\n",
    "learners = Learners(tax_lookup, seeds=seeds)\n",
    "learners.train((X, y, depth_order[:, -1]), \n",
    "               n_cpts_range=range(40, 70, 2),\n",
    "               delta=2e-3,\n",
    "               dest_dir_model=dest_dir_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
