[
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\nLoading\n\n\n\n\n\n\n\nPyTorch data loaders and transforms\n\n\n\n\n\n\n\nSelection\n\n\n\n\n\n\n\nTransform\n\n\n\n\n\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "api/vis/core.html",
    "href": "api/vis/core.html",
    "title": "",
    "section": "",
    "text": "Maplotlib charts\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nfrom mirzai.data.loading import load_kssl\nfrom mirzai.data.selection import get_y_by_order\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import EngFormatter\nfrom matplotlib import ticker\nfrom fastcore.test import *\n:::\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nPRIMARY_COLOR = '#333'\nACCENT_COLOR = 'firebrick'\nDEFAULT_STYLE = {\n    'axes.linewidth': 0.5,\n    'axes.facecolor': 'white',\n    'axes.ymargin': 0.11,\n    'font.size': 8,\n    \n    'axes.spines.bottom': True,\n    'axes.spines.left': False,\n    'axes.spines.right': False,\n    'axes.spines.top': False,\n    'axes.grid': True,\n    \n    'grid.color': 'black',\n    'grid.linewidth': 0.2,\n    'grid.linestyle': '-',\n\n    'xtick.bottom': True,\n    'xtick.top': False,\n    'xtick.direction': 'out',\n    'xtick.major.size': 5,\n    'xtick.major.width': 1,\n    'xtick.minor.size': 3,\n    'xtick.minor.width': 0.5,\n    'xtick.minor.visible': True,\n        \n    'ytick.left': True,\n    'ytick.right': False, \n    'ytick.direction': 'in',\n    'ytick.major.size': 5,\n    'ytick.major.width': 1,\n    'ytick.minor.size': 3,\n    'ytick.minor.width': 0.5,\n    'ytick.minor.visible': True\n}\n\ncentimeter = 1/2.54  # centimeters in inches\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef set_style(style:dict # Dictionary of plt.rcParams\n             ):\n    for k, v in style.items():\n        plt.rcParams[k] = v \n:::\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef plot_spectra(X:np.ndarray, # Spectra (n_samples, n_wavenumbers)\n                 X_names:np.ndarray, # Wavenumbers (n_wavenumbers)\n                 figsize=(18, 5), # Wavenumbers\n                 sample=20): # Size of random subset\n    \"\"\"Plot Mid-infrared spectra\"\"\"\n    fig, ax = plt.subplots(figsize=figsize)\n    idx = np.random.randint(X.shape[0], size=sample)\n    ax.set_xlim(np.max(X_names), np.min(X_names))\n    ax.set(xlabel='Wavenumber', ylabel='Absorbance')\n    ax.set_axisbelow(True)\n    ax.grid(True, which='both')\n    _ = ax.plot(X_names, X[idx, :].T)\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef summary_plot(y:np.ndarray, # Target variable (n_samples)\n                 depth_order:np.ndarray, # Soil and Depth (n_samples, 2)\n                 tax_lookup:dict, # {'alfisols': 0,'mollisols': 1, ...}\n                ):\n    p = plt.rcParams\n    p[\"font.size\"] = 8\n\n    p[\"axes.linewidth\"] = 1\n    p[\"axes.facecolor\"] = \"white\"\n    p[\"axes.ymargin\"] = 0.1\n    p[\"axes.spines.bottom\"] = True\n    p[\"axes.spines.left\"] = False\n    p[\"axes.spines.right\"] = False\n    p[\"axes.spines.top\"] = False\n\n    p[\"axes.grid\"] = True\n    p[\"grid.color\"] = \"black\"\n    p[\"grid.linewidth\"] = 0.2\n    p['grid.linestyle'] = '--'\n\n    p[\"ytick.left\"] = True\n    p[\"ytick.right\"] = True\n    p[\"ytick.major.size\"] = 0\n    p[\"ytick.major.width\"] = 1\n    p[\"ytick.minor.size\"] = 0\n    p[\"ytick.minor.width\"] = 0.5\n    p[\"ytick.minor.visible\"] = False\n\n    fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2, gridspec_kw={'width_ratios': [2, 2]},\n                                   sharey=True, figsize=(15*centimeter, 8*centimeter), dpi=600)\n\n    y_by_order, count_by_order, idx_order = get_y_by_order(y, depth_order[:, 1], tax_lookup)\n    y_labels = np.array([k.capitalize() for k, v in tax_lookup.items()])[idx_order]\n\n    rects = ax1.barh(y_labels, count_by_order,\n                     align='center',\n                     height=0.65,\n                     color=PRIMARY_COLOR)\n\n\n    for i, v in enumerate(count_by_order):\n        offset = 100 if i < len(count_by_order)-1 else -4000\n        color = PRIMARY_COLOR if i < len(count_by_order)-1 else \"white\"\n        ax1.text(v + offset, i - 0.01 , str(v),\n                verticalalignment='center',\n                horizontalalignment='right',\n                color=color, fontweight='normal', size=6)\n\n    for ax in [ax1, ax2]:\n        ax.xaxis.set_major_locator(ticker.MaxNLocator(4))\n        ax.xaxis.set_minor_locator(ticker.MaxNLocator(20))\n\n\n    ax1.tick_params(axis='y', which='major', pad=30)\n    ax1.set_xlabel('← Number of samples', loc='left')\n    ax1.set_ylabel('Taxonomic order')\n    formatter1 = EngFormatter(places=0, sep=\"\\N{THIN SPACE}\")  # U+2009\n    ax1.xaxis.set_major_formatter(formatter1)\n    ax1.set_yticklabels(y_labels, fontdict={'horizontalalignment': 'center'})\n    ax1.yaxis.tick_right()\n    ax1.invert_xaxis()\n    ax1.set_title('(a)', loc='left')\n\n    boxplot = ax2.boxplot(y_by_order, sym='.', positions=range(13), vert=False,\n                        patch_artist=True)\n    ax2.set_xlabel('Exchangeable Potassium ($cmol(+)kg^{-1}$) →', loc='right')\n\n    for median in boxplot['medians']:\n        median.set(color='white', linewidth=1)\n\n    for box in boxplot['boxes']:\n            box.set(facecolor=PRIMARY_COLOR)\n\n    for flier in boxplot['fliers']:\n        flier.set(markersize='1.5', markeredgecolor=\"tab:red\", alpha=0.3, zorder=-1)\n\n    ax2.set_xscale('log')\n    ax2.set_title('(b)', loc='left')\n    ax2.yaxis.set_ticks_position('none')\n\n    plt.tight_layout()\n    #plt.savefig(os.path.join(IMG_PATH, 'data-summary.png'), dpi=600, transparent=True, format='png')\n:::\nTo see an example of use, see Paper with code / 1. Exploratory Data Analysis\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef plot_validation_curve(x, losses, ax=None, plot_kwargs={}, fill_between_kwargs={}):\n    Y = np.mean(np.array(losses), axis=0)\n    SD = np.std(np.array(losses), axis=0) \n    ax.fill_between(x, Y + SD, Y - SD, **fill_between_kwargs)\n    ax.plot(x, Y, **plot_kwargs) \n    return(ax)\n:::\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef plot_learning_curve(x, losses_train, losses_valid, ax=None,  train_kwargs={}, valid_kwargs={}):\n    if ax is None:\n        ax = plt.gca()\n    ax.plot(x, losses_train, label='Training', **train_kwargs) \n    ax.plot(x, losses_valid, label='Validation', **valid_kwargs) \n    ax.set_yscale('log')\n    ax.set_xscale('log')\n    return(ax)\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef plot_capacity(x, capacity, ax=None, **kwargs):\n    if ax is None:\n            ax = plt.gca()\n    ax.bar(x, capacity, width=0.15*np.array(x), color=PRIMARY_COLOR, zorder=99, **kwargs)\n    ax.set_yscale('log')\n    ax.set_xscale('log')\n    # ax.spines.bottom.set_visible(True) \n    return(ax)\n:::"
  },
  {
    "objectID": "api/data/selection.html",
    "href": "api/data/selection.html",
    "title": "",
    "section": "",
    "text": "Utility function to select data subset based on target, features and auxiliary data (e.g. Soil Taxonomy order) - order: 2\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nfrom pathlib import Path\nimport pickle\nimport numpy as np\nfrom fastcore.test import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef select_y(data:tuple, # (X, y, X_id, depth_order)\n             low:float=0.12, # Lowest limit\n             high:float=999 # Highest limit\n            ):\n    \"\"\"Select data based on the limit values of the target\"\"\"\n    X, y, X_id, depth_order = data\n    idx = np.logical_and((y >= low), (y <= high))\n    return X[idx, :], y[idx], X_id[idx], depth_order[idx, :]\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef select_tax_order(data:tuple, # (X, y, X_id, depth_order)\n                     tax_order:int=None # Value between 0 and 12\n                    ):\n    \"\"\"Select data based on Soil Taxonomy order\"\"\"\n    X, y, X_id, depth_order = data\n    if tax_order:\n        idx = depth_order[:, 1] == tax_order\n        return X[idx, :], y[idx], X_id[idx], depth_order[idx, :]\n    else:\n        return data\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef select_X(data:tuple, # (X, y, X_id, depth_order)\n             low:int=0 # Lowest absorbance value\n            ):\n    \"\"\"Select data based on the limit values (only low) of the features\"\"\"\n    X, y, X_id, depth_order = data\n    idx = np.min(X, axis=1) > low\n    return X[idx, :], y[idx], X_id[idx], depth_order[idx, :]\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef get_y_by_order(y, tax_order, tax_lookup):\n    tax_values, count_by_order = np.unique(tax_order, return_counts=True)\n    idx_order = count_by_order.argsort()\n\n    y_by_order = []\n    for tax in tax_values[idx_order]:\n        mask_order = tax_order == tax\n        y_by_order.append(y[mask_order])\n\n    return (y_by_order, count_by_order[idx_order], idx_order)\n:::"
  },
  {
    "objectID": "api/data/transform.html",
    "href": "api/data/transform.html",
    "title": "",
    "section": "",
    "text": "Utility function to transform features and target - order: 3\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\n%load_ext autoreload\n%autoreload 2\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\n#nbdev_comment from __future__ import annotations\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.signal import savgol_filter\nfrom fastcore.test import *\n\nfrom mirzai.data.loading import load_kssl\nfrom mirzai.vis.core import plot_spectra\n:::\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef log_transform_y(data:tuple # (X, y, X_id, depth_order)\n                   ):\n    \"\"\"\n    Log-10 transform of the target value\n\n    Takes and returns all (X, y, X_id, depth_order) tuple to be able to pipe the function\n    \"\"\"\n    X, y, X_id, depth_order = data\n    y = np.log10(y)\n    return X, y, X_id, depth_order\n:::\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nCO2_REGION = [2389,  2269]\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass TakeDerivative(BaseEstimator, TransformerMixin):\n    \"\"\"Creates scikit-learn derivation custom transformer\n\n    Args:\n        window_length: int, optional\n            Specify savgol filter smoothing window length\n\n        polyorder: int, optional\n            Specify order of the polynom used to interpolate derived signal\n\n        deriv: int, optional\n            Specify derivation degree\n\n    Returns:\n        scikit-learn custom transformer\n    \"\"\"\n    def __init__(self, window_length=11, polyorder=1, deriv=1):\n        self.window_length = window_length\n        self.polyorder = polyorder\n        self.deriv = deriv\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return savgol_filter(X, self.window_length, self.polyorder, self.deriv)\n:::\n\nsrc_dir = 'test'\nfnames = ['spectra-features-smp.npy', 'spectra-wavenumbers-smp.npy', \n          'depth-order-smp.npy', 'target-smp.npy', \n          'tax-order-lu-smp.pkl', 'spectra-id-smp.npy']\n\nX, X_names, depth_order, y, tax_lookup, X_id = load_kssl(src_dir, fnames=fnames)\n\n\ntfm = TakeDerivative()\nplot_spectra(tfm.fit_transform(X), X_names, figsize=(12,4))\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass SNV(BaseEstimator, TransformerMixin):\n    \"\"\"Creates scikit-learn SNV custom transformer\n\n    Args:\n        None\n\n    Returns:\n        scikit-learn custom transformer\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        mean, std = np.mean(X, axis=1).reshape(-1, 1), np.std(X, axis=1).reshape(-1, 1)\n        return (X - mean)/std\n:::\n\ntfm = SNV()\nplot_spectra(tfm.fit_transform(X), X_names, figsize=(12,4))\n\n\n\n\n\nclass Center(BaseEstimator, TransformerMixin):\n    \"\"\"Creates scikit-learn Centering custom transformer\n\n    Args:\n        None\n\n    Returns:\n        scikit-learn custom transformer\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X - np.mean(X, axis=1).reshape(-1, 1)\n\n\ntfm = Center()\nplot_spectra(tfm.fit_transform(X), X_names, figsize=(12,4))\n\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass DropSpectralRegions(BaseEstimator, TransformerMixin):\n    \"\"\"Creates scikit-learn custom transformer dropping specific spectral region(s)\n\n    Args:\n        wavenumbers: list\n            List of wavenumbers where absorbance measured\n\n        regions: list\n            List of region(s) to drop\n\n    Returns:\n        scikit-learn custom transformer\n    \"\"\"\n    def __init__(self, wavenumbers, regions=[2389, 2269]):\n        self.wavenumbers = wavenumbers\n        self.regions = regions\n\n    def _sanitize(self, regions):\n        nb_regions = len(np.array(regions).shape)\n        return np.array([regions]) if nb_regions == 1 else np.array(regions)\n\n    def _exists(self, wavenumbers, regions):\n        for wn in regions.flatten():\n            assert wn in wavenumbers, 'Wavenumber \"{}\" does not exist'.format(wn)\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        regions = self._sanitize(self.regions)\n        X_transformed = np.copy(X)\n        self._exists(self.wavenumbers, regions)\n        for region in regions:\n            high, low = region\n            mask = (self.wavenumbers <= high) & (self.wavenumbers >= low)\n            X_transformed[:, mask] = 0\n\n        return X_transformed\n:::\n\ntfm = DropSpectralRegions(X_names, regions=CO2_REGION)\nplot_spectra(tfm.fit_transform(X), X_names, figsize=(12,4))"
  },
  {
    "objectID": "api/data/loading.html",
    "href": "api/data/loading.html",
    "title": "",
    "section": "",
    "text": "Utility function to load MIRS spectra, measured exchangeable potassium and auxiliary data such as depth and Soil Taxonomy order - order: 1\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\n#nbdev_comment from __future__ import annotations\nfrom pathlib import Path\nimport pickle\nimport numpy as np\nfrom fastcore.test import *\nfrom typing import List\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef load_kssl(src_dir:str, # folder path containing data\n              fnames:List[str]=['spectra-features.npy', 'spectra-wavenumbers.npy', # filenames to open (in order)\n                                'depth-order.npy', 'target.npy',\n                                'tax-order-lu.pkl', 'spectra-id.npy'],\n             loaders_lut:dict={'.npy': np.load, '.pkl': pickle.load} # loaders lookup table\n             ):\n    \"\"\"\n    Function loading USDA KSSL dataset focusing here on Exchangeable Potassium (analyte_id=725).\n\n    Returns:\n        A tuple (X, X_names, depth_order, y, tax) with:\n            X: spectra (numpy.ndarray)\n            X_names: spectra wavenumbers (numpy.ndarray)\n            depth_order: depth and order of samples (numpy.ndarray)\n            y: exchangeable potassium content (numpy.ndarray)\n            tax_lookup: look up table order_id -> order_name (Dictionary)\n            X_id: unique id of spectra\n    \"\"\"\n    fnames = [Path(src_dir)/fname for fname in fnames]\n    loaders = [loaders_lut[fname.suffix] for fname in fnames]\n    return [loader(open(fname, 'rb')) for loader, fname in zip(loaders, fnames)]\n:::\nLoads in one call all required data: the Mid-Infrared spectra (the features), associated exchangeable potassium wet chemistry (the target) and additional data such as wavenumbers name, soil depth and others.\nFor instance to open a subsample of the dataset (see setup to download the full dataset):\n\nsrc_dir = 'test'\nfnames = ['spectra-features-smp.npy', 'spectra-wavenumbers-smp.npy', \n          'depth-order-smp.npy', 'target-smp.npy', \n          'tax-order-lu-smp.pkl', 'spectra-id-smp.npy']\n\nX, X_names, depth_order, y, tax_lookup, X_id = load_kssl(src_dir, fnames=fnames)\n\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\nprint(f'Wavenumbers:\\n {X_names}')\nprint(f'depth_order (first 3 rows):\\n {depth_order[:3, :]}')\nprint(f'Taxonomic order lookup:\\n {tax_lookup}')\n\nX shape: (100, 1764)\ny shape: (100,)\nWavenumbers:\n [3999 3997 3995 ...  603  601  599]\ndepth_order (first 3 rows):\n [[ 0.  1.]\n [19.  4.]\n [43. 12.]]\nTaxonomic order lookup:\n {'alfisols': 0, 'mollisols': 1, 'inceptisols': 2, 'entisols': 3, 'spodosols': 4, 'undefined': 5, 'ultisols': 6, 'andisols': 7, 'histosols': 8, 'oxisols': 9, 'vertisols': 10, 'aridisols': 11, 'gelisols': 12}\n\n\n\ntest_eq(X.shape, (100, 1764))\ntest_eq(y.shape, (100,))\ntest_eq(len(X_names), 1764)\ntest_eq(depth_order.shape, (100,2))\ntest_eq(len(tax_lookup), 13)"
  },
  {
    "objectID": "api/data/torch.html",
    "href": "api/data/torch.html",
    "title": "",
    "section": "",
    "text": "PyTorch DataLoaders, DataSet and transforms - order: 4\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\n#nbdev_comment from __future__ import annotations\nimport numpy as np\n\nfrom fastcore.test import *\n\nfrom mirzai.data.loading import load_kssl\nfrom mirzai.data.selection import (select_y, select_tax_order, select_X)\nfrom mirzai.data.transform import (log_transform_y, SNV)\n\nfrom sklearn.model_selection import train_test_split\n\nfrom fastcore.transform import compose\n\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\n\n/Users/franckalbinet/mambaforge/envs/mirzai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n:::\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass SpectralDataset(Dataset):\n    def __init__(self, X, y, tax_order, transform=None):\n        self.X = X\n        self.y = y\n        self.tax_order = tax_order\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        X = self.X[None, idx, :]\n        y = self.y[None, idx]\n        tax_order = self.tax_order[None, idx]\n        if self.transform:\n            X = self.transform(X)\n        return X.astype(np.float32), y.astype(np.float32), tax_order.astype(np.intc)\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass DataLoaders():\n    def __init__(self, *args, transform=None, batch_size=32):\n        \"\"\"\n        Convert numpy error to Pytorch data loaders (generators)\n        Args:\n            *args: one or many tuple as ((X_train, y_train, tax_order), (X_test, y_test, tax_order))\n            transform: callable class (__class__)\n\n        Returns:\n            (training_generator, validation_generator)\n        \"\"\"\n        self.data = args\n        self.batch_size = batch_size\n        self.transform = transform if transform else Noop()\n\n    def loaders(self):\n        return (DataLoader(SpectralDataset(X, y, tax_order, transform=self.transform), \n                           batch_size=self.batch_size,\n                           drop_last=False)\n                for X, y, tax_order in self.data)\n:::\n\n\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass SNV_transform():\n    def __init__(self):\n        None\n    def __call__(self, spectrum):\n        return SNV().fit_transform(spectrum)\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nclass Noop():\n    def __init__(self):\n        None\n    def __call__(self, X):\n        return X\n:::\n\n\n\n\n\n\nsrc_dir = 'test'\nfnames = ['spectra-features-smp.npy', 'spectra-wavenumbers-smp.npy', \n          'depth-order-smp.npy', 'target-smp.npy', \n          'tax-order-lu-smp.pkl', 'spectra-id-smp.npy']\n\nX, X_names, depth_order, y, tax_lookup, X_id = load_kssl(src_dir, fnames=fnames)\ntransforms = [select_y, select_tax_order, select_X, log_transform_y]\n\ndata = X, y, X_id, depth_order\nX, y, X_id, depth_order = compose(*transforms)(data)\n\n\n\n\n\ndata = train_test_split(X, y, depth_order[:, 1], test_size=0.1, random_state=42)\nX_train, X_test, y_train, y_test, tax_order_train, tax_order_test = data\n\n\ndata = train_test_split(X_train, y_train, tax_order_train, test_size=0.1, random_state=42)\nX_train, X_valid, y_train, y_valid, tax_order_train, tax_order_valid = data\n\n\n\n\n\ndls = DataLoaders((X_train, y_train, tax_order_train), \n                  (X_valid, y_valid, tax_order_valid), \n                  (X_test, y_test, tax_order_test), transform=SNV_transform())\n\ntraining_generator, validation_generator, test_generator = dls.loaders()\n\n\n\n\n\nfor features, target, tax in training_generator:\n    print(f'Batch of features (spectra): {features.shape}')\n    print(f'Batch of targets: {target.shape}')\n    print(f'Batch of Soil taxonomy orders id: {tax.shape}')\n\nBatch of features (spectra): torch.Size([32, 1, 1764])\nBatch of targets: torch.Size([32, 1])\nBatch of Soil taxonomy orders id: torch.Size([32, 1])\nBatch of features (spectra): torch.Size([31, 1, 1764])\nBatch of targets: torch.Size([31, 1])\nBatch of Soil taxonomy orders id: torch.Size([31, 1])\n\n\n\nfor features, target, _ in validation_generator:\n    print(f'Batch of features (spectra): {features.shape}')\n    print(f'Batch of targets: {target.shape}')\n\nBatch of features (spectra): torch.Size([8, 1, 1764])\nBatch of targets: torch.Size([8, 1])\n\n\n\nfor features, target, _ in test_generator:\n    print(f'Batch of features (spectra): {features.shape}')\n    print(f'Batch of targets: {target.shape}')\n\nBatch of features (spectra): torch.Size([8, 1, 1764])\nBatch of targets: torch.Size([8, 1])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\n:::"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "",
    "section": "Install",
    "text": "Install\npip install mirzai"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:"
  }
]